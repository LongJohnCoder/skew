// The same operator precedence as C for the most part
enum Precedence {
  LOWEST,
  COMMA,
  ASSIGN,
  LOGICAL_OR,
  LOGICAL_AND,
  BITWISE_OR,
  BITWISE_XOR,
  BITWISE_AND,
  EQUAL,
  COMPARE,
  SHIFT,
  ADD,
  MULTIPLY,
  UNARY_PREFIX,
  UNARY_POSTFIX,
  MEMBER,
}

enum AllowEmpty {
  NO,
  YES,
}

enum StatementHint {
  NORMAL,
  IN_ENUM,
  IN_OBJECT,
  IN_SWITCH,
}

enum TokenScan {
  NORMAL,
  STOP_BEFORE_NEXT_STATEMENT,
}

// Parser recovery is done by skipping to the next closing token after an error
bool scanForToken(ParserContext context, TokenKind kind, TokenScan tokenScan) {
  if (context.expect(kind)) {
    return true;
  }

  // Scan until the next closing token
  while (!context.peek(TokenKind.END_OF_FILE)) {
    TokenKind currentKind = context.current().kind;

    if (currentKind == TokenKind.RIGHT_PARENTHESIS ||
        currentKind == TokenKind.RIGHT_BRACKET ||
        currentKind == TokenKind.RIGHT_BRACE ||
        currentKind == TokenKind.SEMICOLON && tokenScan == TokenScan.STOP_BEFORE_NEXT_STATEMENT) {
      return context.eat(kind);
    }

    // Optionally recover parsing before the next statement if unambiguous
    if (tokenScan == TokenScan.STOP_BEFORE_NEXT_STATEMENT && (
        currentKind == TokenKind.ASSERT ||
        currentKind == TokenKind.BREAK ||
        currentKind == TokenKind.CASE ||
        currentKind == TokenKind.CLASS ||
        currentKind == TokenKind.CONTINUE ||
        currentKind == TokenKind.DO ||
        currentKind == TokenKind.ENUM ||
        currentKind == TokenKind.EXPORT ||
        currentKind == TokenKind.FINAL ||
        currentKind == TokenKind.FOR ||
        currentKind == TokenKind.IF ||
        currentKind == TokenKind.IMPORT ||
        currentKind == TokenKind.INLINE ||
        currentKind == TokenKind.INTERFACE ||
        currentKind == TokenKind.NAMESPACE ||
        currentKind == TokenKind.OVERRIDE ||
        currentKind == TokenKind.PRIVATE ||
        currentKind == TokenKind.PROTECTED ||
        currentKind == TokenKind.PUBLIC ||
        currentKind == TokenKind.RETURN ||
        currentKind == TokenKind.STATIC ||
        currentKind == TokenKind.STRUCT ||
        currentKind == TokenKind.SWITCH ||
        currentKind == TokenKind.USING ||
        currentKind == TokenKind.VIRTUAL ||
        currentKind == TokenKind.WHILE)) {
      return true;
    }

    context.next();
  }

  return false;
}

enum AllowLambda {
  NO,
  YES,
}

Node parseGroup(ParserContext context, AllowLambda allowLambda) {
  Token token = context.current();
  if (!context.expect(TokenKind.LEFT_PARENTHESIS)) return null;
  if (allowLambda == AllowLambda.NO || !context.eat(TokenKind.RIGHT_PARENTHESIS)) {
    Node value = pratt.parse(context, Precedence.LOWEST);
    scanForToken(context, TokenKind.RIGHT_PARENTHESIS, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
    return value;
  }
  if (!context.peek(TokenKind.LAMBDA)) {
    context.expect(TokenKind.LAMBDA);
    return Node.createError().withRange(context.spanSince(token.range));
  }
  return Node.createSequence({}).withRange(context.spanSince(token.range));
}

Node parseName(ParserContext context) {
  Token token = context.current(); if (!context.expect(TokenKind.IDENTIFIER)) return null;
  return Node.createName(token.text).withRange(token.range);
}

Node parseBlock(ParserContext context, StatementHint hint) {
  Token token = context.current();
  if (!context.expect(TokenKind.LEFT_BRACE)) return null;
  List<Node> statements = parseStatements(context, hint);
  scanForToken(context, TokenKind.RIGHT_BRACE, TokenScan.NORMAL);
  return Node.createBlock(statements).withRange(context.spanSince(token.range));
}

Node parseBlockOrStatement(ParserContext context) {
  if (context.peek(TokenKind.LEFT_BRACE)) return parseBlock(context, StatementHint.NORMAL);
  Node statement = parseStatement(context, StatementHint.NORMAL); if (statement == null) return null;
  return Node.createBlock({ statement }).withRange(statement.range);
}

Node parseLambdaBlock(ParserContext context) {
  if (context.peek(TokenKind.LEFT_BRACE)) {
    return parseBlock(context, StatementHint.NORMAL);
  }
  if (context.peek(TokenKind.RIGHT_PARENTHESIS) ||
      context.peek(TokenKind.COMMA) ||
      context.peek(TokenKind.SEMICOLON)) {
    return Node.createBlock({});
  }
  Node value = pratt.parse(context, Precedence.COMMA);
  return Node.createBlock({ Node.createReturn(value).withRange(value.range) }).withRange(value.range);
}

Node parseCaseStatement(ParserContext context) {
  Token token = context.current();
  List<Node> values = {};
  if (!context.eat(TokenKind.DEFAULT)) {
    if (!context.expect(TokenKind.CASE)) return null;
    do {
      // Make sure we don't parse an initializer expression here. The user is
      // likely in the middle of typing a case statement and trying to parse an
      // initializer expression will generate many confusing errors as the
      // parser tries to interpret the case block as an initializer expression.
      // An initializer expression here will still work if it's wrapped in
      // parentheses.
      if (context.peek(TokenKind.LEFT_BRACE)) {
        context.unexpectedToken();
        values.push(Node.createError()); // Make sure this case doesn't look like a default case
        break;
      }

      values.push(pratt.parse(context, Precedence.COMMA));
    } while (context.eat(TokenKind.COMMA));
  }
  Node block = parseBlock(context, StatementHint.NORMAL); if (block == null) return null;
  return Node.createCase(values, block).withRange(context.spanSince(token.range));
}

List<Node> parseStatements(ParserContext context, StatementHint hint) {
  List<Node> statements = {};
  while (!context.peek(TokenKind.RIGHT_BRACE) && !context.peek(TokenKind.END_OF_FILE)) {
    if (hint == StatementHint.IN_ENUM) {
      Node declaration = parseEnumValueDeclaration(context); if (declaration == null) break;
      statements.push(declaration);
      if (!context.eat(TokenKind.COMMA)) break;
    } else {
      Node statement = hint == StatementHint.IN_SWITCH ? parseCaseStatement(context) : parseStatement(context, hint); if (statement == null) break;
      statements.push(statement);
    }
  }
  return statements;
}

Node parseArgumentVariables(ParserContext context) {
  Token token = context.current();
  List<Node> arguments = {};
  if (!context.expect(TokenKind.LEFT_PARENTHESIS)) return null;
  while (!context.peek(TokenKind.RIGHT_PARENTHESIS)) {
    if (arguments.length > 0 && !context.expect(TokenKind.COMMA)) break;
    Node type = parseType(context);
    Node name = parseName(context); if (name == null) break;
    arguments.push(Node.createVariable(name, type, null).withRange(Range.span(type.range, name.range)));
  }
  scanForToken(context, TokenKind.RIGHT_PARENTHESIS, TokenScan.NORMAL);
  return Node.createNodeList(arguments).withRange(context.spanSince(token.range));
}

Node parseType(ParserContext context) {
  return pratt.parse(context, Precedence.MEMBER - 1);
}

Node parseEnumValueDeclaration(ParserContext context) {
  Node name = parseName(context); if (name == null) return null;
  Node value = context.eat(TokenKind.ASSIGN) ? pratt.parse(context, Precedence.COMMA) : null;
  return Node.createVariable(name, null, value).withRange(context.spanSince(name.range));
}

Node parseParameter(ParserContext context) {
  Token token = context.current();
  Node name = parseName(context); if (name == null) return null;
  Node bound = context.eat(TokenKind.IS) ? pratt.parse(context, Precedence.COMMA) : null;
  return Node.createParameter(name, bound).withRange(context.spanSince(token.range));
}

Node parseParameters(ParserContext context) {
  Token token = context.current();
  List<Node> parameters = {};
  if (!context.eat(TokenKind.START_PARAMETER_LIST)) return null;
  while (parameters.length == 0 || !context.peek(TokenKind.END_PARAMETER_LIST)) {
    if (parameters.length > 0 && !context.expect(TokenKind.COMMA)) break;
    Node parameter = parseParameter(context); if (parameter == null) break;
    parameters.push(parameter);
  }
  scanForToken(context, TokenKind.END_PARAMETER_LIST, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
  return Node.createNodeList(parameters).withRange(context.spanSince(token.range));
}

enum AllowTrailingComma {
  NO,
  YES,
}

List<Node> parseArgumentList(ParserContext context, TokenKind left, TokenKind right, AllowTrailingComma comma) {
  List<Node> values = {};
  if (!context.expect(left)) return values;
  while (!context.peek(right)) {
    if (comma == AllowTrailingComma.NO && values.length > 0 && !context.expect(TokenKind.COMMA)) break;
    Node value = pratt.parse(context, Precedence.COMMA);
    values.push(value);
    if (value.kind.isError() || comma == AllowTrailingComma.YES && !context.peek(right) && !context.expect(TokenKind.COMMA)) break;
  }
  scanForToken(context, right, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
  return values;
}

List<Node> parseTypeList(ParserContext context, TokenKind end) {
  Token token = context.current();
  List<Node> types = {};
  while (types.length == 0 || !context.peek(end)) {
    // Make sure we don't parse an initializer expression. The user is likely
    // in the middle of typing an object base type list and trying to parse an
    // initializer expression will generate many confusing errors as the parser
    // tries to interpret the object block as an initializer expression.
    if (context.peek(TokenKind.LEFT_BRACE)) {
      context.unexpectedToken();
      break;
    }

    // Commas must come between types
    if (types.length > 0 && !context.eat(TokenKind.COMMA)) {
      context.expect(end); // Expecting the end token here makes more sense than a comma
      break;
    }

    // Also prevent initializer expression parsing after a comma
    if (context.peek(TokenKind.LEFT_BRACE)) {
      context.unexpectedToken();
      break;
    }

    types.push(parseType(context));
  }
  return types;
}

Node parseObject(ParserContext context, NodeKind kind) {
  Token token = context.next();
  Node name = parseName(context); if (name == null) return null;
  Node parameters = parseParameters(context);
  Node bases = context.eat(TokenKind.COLON) ? Node.createNodeList(parseTypeList(context, TokenKind.LEFT_BRACE)) : null;
  Node block = parseBlock(context, StatementHint.IN_OBJECT); if (block == null) return null;
  return Node.createObject(kind, name, parameters, bases, block).withRange(context.spanSince(token.range));
}

Node parseNestedNamespaceBlock(ParserContext context) {
  if (!context.eat(TokenKind.DOT)) {
    return parseBlock(context, StatementHint.NORMAL);
  }
  Node name = parseName(context); // Allow this to be null for autocomplete
  Node block = parseNestedNamespaceBlock(context); if (block == null) return null;
  Range range = context.spanSince((name != null ? name : block).range);
  return Node.createBlock({ Node.createNamespace(name, block).withRange(range) }).withRange(range);
}

Node parseNamespace(ParserContext context) {
  Token token = context.next();
  Node name = parseName(context); if (name == null) return null;
  Node block = parseNestedNamespaceBlock(context); if (block == null) return null;
  return Node.createNamespace(name, block).withRange(context.spanSince(token.range));
}

Node parseExpression(ParserContext context) {
  // Make sure we don't parse an initializer expression. The user is likely
  // trying to type a C-style block statement, which is not supported. An
  // initializer expression wouldn't make sense here anyway since there's no
  // type context yet at the start of an expression statement.
  if (context.peek(TokenKind.LEFT_BRACE)) {
    context.unexpectedToken();
    return null;
  }

  // Parse an expression
  Token token = context.current();
  Node value = pratt.parse(context, Precedence.LOWEST);
  if (!scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT) && context.current().range.start == token.range.start) {
    context.next(); // This is necessary to prevent an infinite loop when the first token of the expression is a syntax error
  }

  assert context.current().range.start >= token.range.end; // Make sure the context was advanced
  return Node.createExpression(value).withRange(context.spanSince(token.range));
}

Node parseModifier(ParserContext context, SymbolFlag flag) {
  Token token = context.next();
  Node name = Node.createName(token.text).withRange(token.range);
  Node block = parseBlockOrStatement(context); if (block == null) return null;
  return Node.createModifier(name, block.removeChildren()).withRange(context.spanSince(token.range));
}

Node parseReturn(ParserContext context) {
  Token token = context.next();
  Node value = null;
  if (!context.eat(TokenKind.SEMICOLON)) {
    value = pratt.parse(context, Precedence.LOWEST);
    scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
  }
  return Node.createReturn(value).withRange(context.spanSince(token.range));
}

Node parseBreak(ParserContext context) {
  Token token = context.next();
  context.expect(TokenKind.SEMICOLON); // No need to use scanForToken() here
  return Node.createBreak().withRange(context.spanSince(token.range));
}

Node parseContinue(ParserContext context) {
  Token token = context.next();
  context.expect(TokenKind.SEMICOLON); // No need to use scanForToken() here
  return Node.createContinue().withRange(context.spanSince(token.range));
}

Node parseAssert(ParserContext context) {
  Token token = context.next();
  Node value = pratt.parse(context, Precedence.LOWEST);
  scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
  return Node.createAssert(value).withRange(context.spanSince(token.range));
}

Node parseSwitch(ParserContext context) {
  Token token = context.next();
  Node value = parseGroup(context, AllowLambda.NO); if (value == null) return null;
  Node block = parseBlock(context, StatementHint.IN_SWITCH); if (block == null) return null;
  return Node.createSwitch(value, block.removeChildren()).withRange(context.spanSince(token.range));
}

Node parseWhile(ParserContext context) {
  Token token = context.next();
  Node value = parseGroup(context, AllowLambda.NO); if (value == null) return null;
  Node block = parseBlockOrStatement(context); if (block == null) return null;
  return Node.createWhile(value, block).withRange(context.spanSince(token.range));
}

Node parseDoWhile(ParserContext context) {
  Token token = context.next();
  Node block = parseBlockOrStatement(context); if (block == null) return null;
  if (!context.expect(TokenKind.WHILE)) return null;
  Node value = parseGroup(context, AllowLambda.NO);
  scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
  return Node.createDoWhile(block, value).withRange(context.spanSince(token.range));
}

Node parseIf(ParserContext context) {
  Token token = context.next();
  Node value = parseGroup(context, AllowLambda.NO); if (value == null) return null;
  Node trueBlock = parseBlockOrStatement(context); if (trueBlock == null) return null;
  Node falseBlock = null;
  if (context.eat(TokenKind.ELSE)) {
    falseBlock = parseBlockOrStatement(context); if (falseBlock == null) return null;
  }
  return Node.createIf(value, trueBlock, falseBlock).withRange(context.spanSince(token.range));
}

Node parseExtension(ParserContext context) {
  Token token = context.next();
  Node name = parseName(context); if (name == null) return null;
  Node block = parseBlock(context, StatementHint.IN_OBJECT); if (block == null) return null;
  return Node.createExtension(name, block).withRange(context.spanSince(token.range));
}

Node parseEnum(ParserContext context) {
  Token token = context.next();
  NodeKind kind = NodeKind.ENUM;
  if (context.peek(TokenKind.IDENTIFIER) && context.current().text == "flags") {
    kind = NodeKind.ENUM_FLAGS;
    context.next();
  }
  Node name = parseName(context); if (name == null) return null;
  Node block = parseBlock(context, StatementHint.IN_ENUM); if (block == null) return null;
  return new Node(kind).withChildren({ name, block }).withRange(context.spanSince(token.range));
}

Node parseVariableCluster(ParserContext context, Node type, Node name) {
  List<Node> variables = {};
  Node start = type;
  while (variables.length == 0 || !context.peek(TokenKind.SEMICOLON) && !context.peek(TokenKind.IN)) {
    if (variables.length > 0 && !context.eat(TokenKind.COMMA)) {
      context.expect(TokenKind.SEMICOLON); // Expecting a semicolon here makes more sense than a comma
      break;
    }
    if (name == null) name = start = parseName(context); if (name == null) break;
    Node value = context.eat(TokenKind.ASSIGN) ? pratt.parse(context, Precedence.COMMA) : null;
    variables.push(Node.createVariable(name, null, value).withRange(context.spanSince(start.range)));
    name = null;
  }
  return Node.createVariableCluster(type, variables).withRange(context.spanSince(type.range));
}

Node parseFor(ParserContext context) {
  Token token = context.next();
  if (!context.expect(TokenKind.LEFT_PARENTHESIS)) return null;
  Node setup = null;
  Node test = null;
  Node update = null;
  do {
    if (!context.peek(TokenKind.SEMICOLON) && !context.peek(TokenKind.RIGHT_PARENTHESIS)) {
      setup = parseType(context);
      if (context.peek(TokenKind.IDENTIFIER)) {
        Node name = parseName(context);
        setup = name != null ? parseVariableCluster(context, setup, name) : null;
        if (setup != null && context.eat(TokenKind.IN)) {
          Node values = pratt.parse(context, Precedence.LOWEST);
          scanForToken(context, TokenKind.RIGHT_PARENTHESIS, TokenScan.NORMAL);
          Node body = parseBlockOrStatement(context); if (body == null) return null;
          List<Node> variables = setup.clusterVariables();
          if (variables.length > 1) syntaxErrorBadForEach(context.log, setup.range);
          Node value = Node.createVariable(variables.get(0).declarationName().remove(), setup.clusterType().remove(), null);
          return Node.createForEach(value, values, body).withRange(context.spanSince(token.range));
        }
      } else if (!context.peek(TokenKind.SEMICOLON)) {
        setup = pratt.resume(context, Precedence.LOWEST, setup);
      }
    }
    if (!context.expect(TokenKind.SEMICOLON)) break;
    if (!context.peek(TokenKind.SEMICOLON) && !context.peek(TokenKind.RIGHT_PARENTHESIS)) test = pratt.parse(context, Precedence.LOWEST);
    if (!context.expect(TokenKind.SEMICOLON)) break;
    if (!context.peek(TokenKind.RIGHT_PARENTHESIS)) update = pratt.parse(context, Precedence.LOWEST);
  } while (false);
  scanForToken(context, TokenKind.RIGHT_PARENTHESIS, TokenScan.NORMAL);
  Node block = parseBlockOrStatement(context); if (block == null) return null;
  return Node.createFor(setup, test, update, block).withRange(context.spanSince(token.range));
}

Node parseSuperCall(ParserContext context) {
  Token token = context.next();
  List<Node> values = parseArgumentList(context, TokenKind.LEFT_PARENTHESIS, TokenKind.RIGHT_PARENTHESIS, AllowTrailingComma.NO);
  return Node.createSuperCall(values).withRange(context.spanSince(token.range));
}

Node parsePossibleTypedDeclaration(ParserContext context, StatementHint hint) {
  Node type = parseType(context);

  // Parse a constructor
  if (hint == StatementHint.IN_OBJECT && type.kind == NodeKind.NAME && context.peek(TokenKind.LEFT_PARENTHESIS)) {
    Node arguments = parseArgumentVariables(context); if (arguments == null) return null;
    Node superInitializer = null;
    Node memberInitializers = null;

    // Parse the initializer list
    if (context.eat(TokenKind.COLON)) {

      // The super initializer can have multiple arguments
      if (context.peek(TokenKind.SUPER)) {
        superInitializer = parseSuperCall(context);
      }

      // Each member initializer has one argument
      if (superInitializer == null || context.eat(TokenKind.COMMA)) {
        List<Node> values = {};
        do {
          Node member = parseName(context); if (member == null) break;
          if (!context.expect(TokenKind.ASSIGN)) break;
          Node value = pratt.parse(context, Precedence.COMMA);
          values.push(Node.createVariable(member, null, value).withRange(context.spanSince(member.range)));
        } while (context.eat(TokenKind.COMMA));
        memberInitializers = Node.createNodeList(values);
      }
    }

    Node block = null;
    if (!context.eat(TokenKind.SEMICOLON)) {
      block = parseBlock(context, StatementHint.NORMAL); if (block == null) return null;
    }
    return Node.createConstructor(type, arguments, block, superInitializer, memberInitializers).withRange(context.spanSince(type.range));
  }

  // If this isn't a typed declaration, just parse an expression statement
  if (!context.peek(TokenKind.IDENTIFIER)) {
    Node value = pratt.resume(context, Precedence.LOWEST, type);
    scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
    return Node.createExpression(value).withRange(context.spanSince(type.range));
  }

  // Parse a typed declaration
  Node name = parseName(context); if (name == null) return null;

  // Function declaration
  if (context.peek(TokenKind.LEFT_PARENTHESIS)) {
    Node arguments = parseArgumentVariables(context); if (arguments == null) return null;
    Node block = null;
    if (!context.eat(TokenKind.SEMICOLON)) {
      block = parseBlock(context, StatementHint.NORMAL); if (block == null) return null;
    }
    return Node.createFunction(name, arguments, block, type).withRange(context.spanSince(type.range));
  }

  // Variable declaration
  Node cluster = parseVariableCluster(context, type, name);
  scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
  Node last = cluster.children.get(cluster.children.length - 1);
  last.withRange(context.spanSince(last.range));
  return cluster;
}

Node parseUsing(ParserContext context) {
  Token token = context.next();
  Node name = parseName(context);
  if (name == null) {
    scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
    Range range = context.spanSince(token.range);
    return Node.createExpression(Node.createError().withRange(range)).withRange(range);
  }
  if (!context.eat(TokenKind.ASSIGN)) {
    Node value = pratt.resume(context, Precedence.LOWEST, name);
    scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
    return Node.createUsingNamespace(value).withRange(context.spanSince(token.range));
  } else {
    Node value = pratt.parse(context, Precedence.LOWEST);
    scanForToken(context, TokenKind.SEMICOLON, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
    return Node.createUsingAlias(name, value).withRange(context.spanSince(token.range));
  }
}

bool looksLikeLambdaArguments(Node node) {
  if (node.kind == NodeKind.SEQUENCE) {
    int i;
    for (i = 0; i < node.children.length; i++) {
      if (node.children.get(i).kind != NodeKind.NAME) {
        return false;
      }
    }
    return true;
  }
  return false;
}

Node createLambdaFromNames(List<Node> names, Node block) {
  int i;
  for (i = 0; i < names.length; i++) {
    Node name = names.get(i);
    assert name.kind == NodeKind.NAME;
    names.set(i, Node.createVariable(name, null, null).withRange(name.range));
  }
  return Node.createLambda(names, block);
}

bool looksLikeType(Node node) {
  switch (node.kind) {
    case NodeKind.DOT { return looksLikeType(node.dotTarget()); }
    case NodeKind.NAME, NodeKind.PARAMETERIZE, NodeKind.FUNCTION_TYPE { return true; }
    default { return false; }
  }
}

Node parseStatement(ParserContext context, StatementHint hint) {
  switch (context.current().kind) {
    case TokenKind.ASSERT { return parseAssert(context); }
    case TokenKind.BREAK { return parseBreak(context); }
    case TokenKind.CLASS { return parseObject(context, NodeKind.CLASS); }
    case TokenKind.CONTINUE { return parseContinue(context); }
    case TokenKind.DO { return parseDoWhile(context); }
    case TokenKind.ENUM { return parseEnum(context); }
    case TokenKind.EXPORT { return parseModifier(context, SymbolFlag.EXPORT); }
    case TokenKind.FINAL { return parseModifier(context, SymbolFlag.FINAL); }
    case TokenKind.FOR { return parseFor(context); }
    case TokenKind.IDENTIFIER, TokenKind.VAR { return parsePossibleTypedDeclaration(context, hint); }
    case TokenKind.IF { return parseIf(context); }
    case TokenKind.IMPORT { return parseModifier(context, SymbolFlag.IMPORT); }
    case TokenKind.IN { return parseExtension(context); }
    case TokenKind.INLINE { return parseModifier(context, SymbolFlag.INLINE); }
    case TokenKind.INTERFACE { return parseObject(context, NodeKind.INTERFACE); }
    case TokenKind.NAMESPACE { return parseNamespace(context); }
    case TokenKind.OVERRIDE { return parseModifier(context, SymbolFlag.OVERRIDE); }
    case TokenKind.PRIVATE { return parseModifier(context, SymbolFlag.PRIVATE); }
    case TokenKind.PROTECTED { return parseModifier(context, SymbolFlag.PROTECTED); }
    case TokenKind.PUBLIC { return parseModifier(context, SymbolFlag.PUBLIC); }
    case TokenKind.RETURN { return parseReturn(context); }
    case TokenKind.STATIC { return parseModifier(context, SymbolFlag.STATIC); }
    case TokenKind.STRUCT { return parseObject(context, NodeKind.STRUCT); }
    case TokenKind.SWITCH { return parseSwitch(context); }
    case TokenKind.USING { return parseUsing(context); }
    case TokenKind.VIRTUAL { return parseModifier(context, SymbolFlag.VIRTUAL); }
    case TokenKind.WHILE { return parseWhile(context); }
    default { return parseExpression(context); }
  }
}

Node parseFile(Log log, List<Token> tokens) {
  ParserContext context = new ParserContext(log, tokens);
  Token token = context.current();
  List<Node> statements = parseStatements(context, StatementHint.NORMAL); if (statements == null) return null;
  if (!context.expect(TokenKind.END_OF_FILE)) return null;
  Range range = context.spanSince(token.range);
  return Node.createFile(Node.createBlock(statements).withRange(range)).withRange(range);
}

class TokenLiteral : ILiteralCallback {
  NodeKind kind;

  override Node run(ParserContext context, Token token) {
    return new Node(kind).withRange(token.range);
  }
}

class IntLiteral : ILiteralCallback {
  int base;

  override Node run(ParserContext context, Token token) {
    double value = parseIntLiteral(token.text, base);
    if (value != value) syntaxErrorInvalidInteger(context.log, token.range, token.text);
    return Node.createInt((int)value).withRange(token.range);
  }
}

class FloatLiteral : ILiteralCallback {
  override Node run(ParserContext context, Token token) {
    return Node.createFloat(parseDoubleLiteral(token.text.slice(0, token.text.length - 1))).withRange(token.range);
  }
}

class DoubleLiteral : ILiteralCallback {
  override Node run(ParserContext context, Token token) {
    return Node.createDouble(parseDoubleLiteral(token.text)).withRange(token.range);
  }
}

class StringLiteral : ILiteralCallback {
  override Node run(ParserContext context, Token token) {
    StringContent result = parseStringLiteral(context.log, token.range, token.text);

    // Don't return null on failure because this doesn't affect the rest of the compilation
    return Node.createString(result != null ? result.value : "").withRange(token.range);
  }
}

class CharacterLiteral : ILiteralCallback {
  override Node run(ParserContext context, Token token) {
    StringContent result = parseStringLiteral(context.log, token.range, token.text);

    // TODO: Do true unicode code point parsing
    if (result != null && result.value.length != 1) {
      syntaxErrorInvalidCharacter(context.log, token.range, token.text);
      result = null;
    }

    // Don't return null on failure because this doesn't affect the rest of the compilation
    return Node.createInt(result != null ? result.value.codeUnitAt(0) : 0).withRange(token.range);
  }
}

class VarLiteral : ILiteralCallback {
  override Node run(ParserContext context, Token token) {
    return Node.createVar().withRange(token.range);
  }
}

class InitializerParselet : IPrefixParselet {
  override Node run(ParserContext context) {
    Token token = context.current();
    List<Node> arguments = parseArgumentList(context, TokenKind.LEFT_BRACE, TokenKind.RIGHT_BRACE, AllowTrailingComma.YES);
    return Node.createInitializer(arguments).withRange(context.spanSince(token.range));
  }
}

class GroupParselet : IPrefixParselet {
  override Node run(ParserContext context) {
    Token token = context.current();
    Node type = parseGroup(context, AllowLambda.YES);
    if (type.kind == NodeKind.NAME && context.eat(TokenKind.LAMBDA)) {
      Node block = parseLambdaBlock(context);
      return createLambdaFromNames({ type }, block).withRange(context.spanSince(token.range));
    }
    if (looksLikeLambdaArguments(type) && context.eat(TokenKind.LAMBDA)) {
      Node block = parseLambdaBlock(context);
      return createLambdaFromNames(type.removeChildren(), block).withRange(context.spanSince(token.range));
    }
    if (looksLikeType(type)) {
      Node value = pratt.parse(context, Precedence.UNARY_PREFIX);
      return Node.createCast(type, value).withRange(context.spanSince(token.range));
    }
    return type;
  }
}

class HookInfix : IInfixParselet {
  override Node run(ParserContext context, Node left) {
    context.next();
    Node middle = pratt.parse(context, Precedence.ASSIGN - 1);
    Node right = context.expect(TokenKind.COLON) ? pratt.parse(context, Precedence.ASSIGN - 1) : Node.createError().withRange(context.spanSince(context.current().range));
    return Node.createHook(left, middle, right).withRange(context.spanSince(left.range));
  }
}

class SequenceInfix : IInfixParselet {
  override Node run(ParserContext context, Node left) {
    List<Node> values = { left };
    while (context.eat(TokenKind.COMMA)) {
      values.push(pratt.parse(context, Precedence.COMMA));
    }
    return Node.createSequence(values).withRange(context.spanSince(left.range));
  }
}

class DotInfix : IInfixParselet {
  override Node run(ParserContext context, Node left) {
    context.next();
    Node name = parseName(context); // Allow this to be null for autocomplete
    return Node.createDot(left, name).withRange(context.spanSince(left.range));
  }
}

class DotPrefix : IPrefixParselet {
  override Node run(ParserContext context) {
    Token token = context.next();
    Node name = parseName(context); // Allow this to be null for autocomplete
    return Node.createDot(null, name).withRange(context.spanSince(token.range));
  }
}

class FnInfix : IInfixParselet {
  override Node run(ParserContext context, Node left) {
    if (!looksLikeType(left)) {
      context.unexpectedToken();
      context.next();
      return Node.createError().withRange(context.spanSince(left.range));
    }
    context.next();
    List<Node> arguments = parseArgumentList(context, TokenKind.LEFT_PARENTHESIS, TokenKind.RIGHT_PARENTHESIS, AllowTrailingComma.YES);
    return Node.createFunctionType(left, arguments).withRange(context.spanSince(left.range));
  }
}

class UnaryPostfix : IPostfixCallback {
  NodeKind kind;

  override Node run(ParserContext context, Node value, Token token) {
    return Node.createUnary(kind, value).withRange(Range.span(value.range, token.range));
  }
}

class UnaryPrefix : IPrefixCallback {
  NodeKind kind;

  override Node run(ParserContext context, Token token, Node value) {
    return Node.createUnary(kind, value).withRange(Range.span(token.range, value.range));
  }
}

class BinaryInfix : IInfixCallback {
  NodeKind kind;

  override Node run(ParserContext context, Node left, Token token, Node right) {
    return Node.createBinary(kind, left, right).withRange(Range.span(left.range, right.range));
  }
}

class CallInfix : IInfixParselet {
  override Node run(ParserContext context, Node left) {
    List<Node> arguments = parseArgumentList(context, TokenKind.LEFT_PARENTHESIS, TokenKind.RIGHT_PARENTHESIS, AllowTrailingComma.NO);
    return Node.createCall(left, arguments).withRange(context.spanSince(left.range));
  }
}

class IndexInfix : IInfixParselet {
  override Node run(ParserContext context, Node left) {
    context.next();
    Node index = pratt.parse(context, Precedence.LOWEST);
    scanForToken(context, TokenKind.RIGHT_BRACKET, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
    return Node.createBinary(NodeKind.INDEX, left, index).withRange(context.spanSince(left.range));
  }
}

class SubstitutionInfix : IInfixParselet {
  override Node run(ParserContext context, Node left) {
    Token token = context.next();
    List<Node> substitutions = parseTypeList(context, TokenKind.END_PARAMETER_LIST);
    if (!context.expect(TokenKind.END_PARAMETER_LIST)) {
      scanForToken(context, TokenKind.END_PARAMETER_LIST, TokenScan.STOP_BEFORE_NEXT_STATEMENT);
      return Node.createError().withRange(context.spanSince(token.range));
    }
    return Node.createParameterize(left, substitutions).withRange(context.spanSince(left.range));
  }
}

class DefaultPrefix : IPrefixParselet {
  override Node run(ParserContext context) {
    Token token = context.next();
    Node type = parseGroup(context, AllowLambda.NO);
    return (type == null ? Node.createError() : Node.createDefault(type)).withRange(context.spanSince(token.range));
  }
}

class SuperCallPrefix : IPrefixParselet {
  override Node run(ParserContext context) {
    return parseSuperCall(context);
  }
}

class NamePrefix : IPrefixParselet {
  override Node run(ParserContext context) {
    Token token = context.next();
    Node name = Node.createName(token.text).withRange(token.range);
    if (context.eat(TokenKind.LAMBDA)) {
      Node block = parseLambdaBlock(context);
      return createLambdaFromNames({ name }, block).withRange(context.spanSince(token.range));
    }
    return name;
  }
}

class LambdaPrefix : IPrefixParselet {
  override Node run(ParserContext context) {
    Token token = context.next();
    Node block = parseLambdaBlock(context);
    return Node.createLambda({}, block).withRange(context.spanSince(token.range));
  }
}

Pratt createParser() {
  Pratt pratt = new Pratt();

  // Literals
  pratt.literal(TokenKind.NULL, new TokenLiteral(NodeKind.NULL));
  pratt.literal(TokenKind.THIS, new TokenLiteral(NodeKind.THIS));
  pratt.literal(TokenKind.TRUE, new TokenLiteral(NodeKind.TRUE));
  pratt.literal(TokenKind.FALSE, new TokenLiteral(NodeKind.FALSE));
  pratt.literal(TokenKind.INT_DECIMAL, new IntLiteral(10));
  pratt.literal(TokenKind.INT_BINARY, new IntLiteral(2));
  pratt.literal(TokenKind.INT_OCTAL, new IntLiteral(8));
  pratt.literal(TokenKind.INT_HEX, new IntLiteral(16));
  pratt.literal(TokenKind.FLOAT, new FloatLiteral());
  pratt.literal(TokenKind.DOUBLE, new DoubleLiteral());
  pratt.literal(TokenKind.STRING, new StringLiteral());
  pratt.literal(TokenKind.CHARACTER, new CharacterLiteral());
  pratt.literal(TokenKind.VAR, new VarLiteral());

  // Unary expressions
  pratt.postfix(TokenKind.INCREMENT, Precedence.UNARY_POSTFIX, new UnaryPostfix(NodeKind.POSTFIX_INCREMENT));
  pratt.postfix(TokenKind.DECREMENT, Precedence.UNARY_POSTFIX, new UnaryPostfix(NodeKind.POSTFIX_DECREMENT));
  pratt.prefix(TokenKind.INCREMENT, Precedence.UNARY_PREFIX, new UnaryPrefix(NodeKind.PREFIX_INCREMENT));
  pratt.prefix(TokenKind.DECREMENT, Precedence.UNARY_PREFIX, new UnaryPrefix(NodeKind.PREFIX_DECREMENT));
  pratt.prefix(TokenKind.PLUS, Precedence.UNARY_PREFIX, new UnaryPrefix(NodeKind.POSITIVE));
  pratt.prefix(TokenKind.MINUS, Precedence.UNARY_PREFIX, new UnaryPrefix(NodeKind.NEGATIVE));
  pratt.prefix(TokenKind.NOT, Precedence.UNARY_PREFIX, new UnaryPrefix(NodeKind.NOT));
  pratt.prefix(TokenKind.TILDE, Precedence.UNARY_PREFIX, new UnaryPrefix(NodeKind.COMPLEMENT));

  // Binary expressions
  pratt.infix(TokenKind.BITWISE_AND, Precedence.BITWISE_AND, new BinaryInfix(NodeKind.BITWISE_AND));
  pratt.infix(TokenKind.BITWISE_OR, Precedence.BITWISE_OR, new BinaryInfix(NodeKind.BITWISE_OR));
  pratt.infix(TokenKind.BITWISE_XOR, Precedence.BITWISE_XOR, new BinaryInfix(NodeKind.BITWISE_XOR));
  pratt.infix(TokenKind.DIVIDE, Precedence.MULTIPLY, new BinaryInfix(NodeKind.DIVIDE));
  pratt.infix(TokenKind.EQUAL, Precedence.EQUAL, new BinaryInfix(NodeKind.EQUAL));
  pratt.infix(TokenKind.GREATER_THAN, Precedence.COMPARE, new BinaryInfix(NodeKind.GREATER_THAN));
  pratt.infix(TokenKind.GREATER_THAN_OR_EQUAL, Precedence.COMPARE, new BinaryInfix(NodeKind.GREATER_THAN_OR_EQUAL));
  pratt.infix(TokenKind.IN, Precedence.COMPARE, new BinaryInfix(NodeKind.IN));
  pratt.infix(TokenKind.LESS_THAN, Precedence.COMPARE, new BinaryInfix(NodeKind.LESS_THAN));
  pratt.infix(TokenKind.LESS_THAN_OR_EQUAL, Precedence.COMPARE, new BinaryInfix(NodeKind.LESS_THAN_OR_EQUAL));
  pratt.infix(TokenKind.LOGICAL_AND, Precedence.LOGICAL_AND, new BinaryInfix(NodeKind.LOGICAL_AND));
  pratt.infix(TokenKind.LOGICAL_OR, Precedence.LOGICAL_OR, new BinaryInfix(NodeKind.LOGICAL_OR));
  pratt.infix(TokenKind.MINUS, Precedence.ADD, new BinaryInfix(NodeKind.SUBTRACT));
  pratt.infix(TokenKind.MULTIPLY, Precedence.MULTIPLY, new BinaryInfix(NodeKind.MULTIPLY));
  pratt.infix(TokenKind.NOT_EQUAL, Precedence.EQUAL, new BinaryInfix(NodeKind.NOT_EQUAL));
  pratt.infix(TokenKind.PLUS, Precedence.ADD, new BinaryInfix(NodeKind.ADD));
  pratt.infix(TokenKind.REMAINDER, Precedence.MULTIPLY, new BinaryInfix(NodeKind.REMAINDER));
  pratt.infix(TokenKind.SHIFT_LEFT, Precedence.SHIFT, new BinaryInfix(NodeKind.SHIFT_LEFT));
  pratt.infix(TokenKind.SHIFT_RIGHT, Precedence.SHIFT, new BinaryInfix(NodeKind.SHIFT_RIGHT));

  // Assignment expressions
  pratt.infixRight(TokenKind.ASSIGN, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN));
  pratt.infixRight(TokenKind.ASSIGN_PLUS, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_ADD));
  pratt.infixRight(TokenKind.ASSIGN_BITWISE_AND, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_BITWISE_AND));
  pratt.infixRight(TokenKind.ASSIGN_BITWISE_OR, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_BITWISE_OR));
  pratt.infixRight(TokenKind.ASSIGN_BITWISE_XOR, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_BITWISE_XOR));
  pratt.infixRight(TokenKind.ASSIGN_DIVIDE, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_DIVIDE));
  pratt.infixRight(TokenKind.ASSIGN_MULTIPLY, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_MULTIPLY));
  pratt.infixRight(TokenKind.ASSIGN_REMAINDER, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_REMAINDER));
  pratt.infixRight(TokenKind.ASSIGN_SHIFT_LEFT, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_SHIFT_LEFT));
  pratt.infixRight(TokenKind.ASSIGN_SHIFT_RIGHT, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_SHIFT_RIGHT));
  pratt.infixRight(TokenKind.ASSIGN_MINUS, Precedence.ASSIGN, new BinaryInfix(NodeKind.ASSIGN_SUBTRACT));

  // Other expressions
  pratt.parselet(TokenKind.LEFT_BRACE, Precedence.LOWEST).prefix = new InitializerParselet();
  pratt.parselet(TokenKind.LEFT_PARENTHESIS, Precedence.LOWEST).prefix = new GroupParselet();
  pratt.parselet(TokenKind.QUESTION_MARK, Precedence.ASSIGN).infix = new HookInfix();
  pratt.parselet(TokenKind.COMMA, Precedence.COMMA).infix = new SequenceInfix();
  pratt.parselet(TokenKind.DOT, Precedence.MEMBER).infix = new DotInfix();
  pratt.parselet(TokenKind.DOT, Precedence.LOWEST).prefix = new DotPrefix();
  pratt.parselet(TokenKind.FN, Precedence.MEMBER).infix = new FnInfix();
  pratt.parselet(TokenKind.LEFT_PARENTHESIS, Precedence.UNARY_POSTFIX).infix = new CallInfix();
  pratt.parselet(TokenKind.LEFT_BRACKET, Precedence.UNARY_POSTFIX).infix = new IndexInfix();
  pratt.parselet(TokenKind.START_PARAMETER_LIST, Precedence.MEMBER).infix = new SubstitutionInfix();
  pratt.parselet(TokenKind.DEFAULT, Precedence.UNARY_PREFIX).prefix = new DefaultPrefix();
  pratt.parselet(TokenKind.SUPER, Precedence.LOWEST).prefix = new SuperCallPrefix();
  pratt.parselet(TokenKind.IDENTIFIER, Precedence.LOWEST).prefix = new NamePrefix();
  pratt.parselet(TokenKind.LAMBDA, Precedence.LOWEST).prefix = new LambdaPrefix();

  return pratt;
}

final Pratt pratt = createParser();
